{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8af87e-36c4-4ff3-8eec-0c2c000c71bb",
   "metadata": {},
   "source": [
    "# Santander Customer Satisfaction\n",
    "As a service business, banking institutions are also resolved into further improving the customer experience wether it be virtual or in-person. Indeed, any improvements they ought to make in their product line shall be directed by a virtuous feedback loop through active listening to their customers. In that vein, this notebook will attempt to build a predictive algorithm to determine what are the customers liking or disliking the service provided (binary target 0/1) given a set of variables. In doing so, we will follow LIME (Local Interpretable Model-agnostic Explanations) principles making it accessible and user-friendly to most readers.\n",
    "\n",
    "## Table of Contents\n",
    "1. Environment set-up\n",
    "    * Importing Libraries\n",
    "    * Loading the data  \n",
    "2. Initial Diagnostics\n",
    "    * Glimpse\n",
    "    * Descriptive Statitics\n",
    "    * Target Variable Analysis\n",
    "    * Predictors Analysis  \n",
    "3. Feature Engineering\n",
    "    * Feature Scaling\n",
    "    * Categorical Encoding\n",
    "4. Dimensionality Reduction\n",
    "    * PCA - Principal Component Analysis\n",
    "    * SVD - Singular Value Decomposition\n",
    "    * LDA - Linear Discriminant Analysis\n",
    "5. Machine Learning set-up\n",
    "8. ML Model Building\n",
    "9. Hyperparameter Tuning\n",
    "10. Final Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5c6de-69d9-4638-a4c3-c51874dde5a8",
   "metadata": {},
   "source": [
    "# 1. Environment Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "biological-skill",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 1.571819,
     "end_time": "2021-06-28T13:06:58.779132",
     "exception": false,
     "start_time": "2021-06-28T13:06:57.207313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Set seed\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "# Time function\n",
    "import time\n",
    "\n",
    "# Regex\n",
    "import re\n",
    "\n",
    "# Statiscal methods\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "\n",
    "# Manipulating & Visualizing Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.impute import SimpleImputer as imp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(12, 8)})\n",
    "\n",
    "# Categorical Encoding\n",
    "import category_encoders as ce\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sampling Methods\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "# ML Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Ensemble Learning\n",
    "import sklearn.ensemble as esmb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Performance metrics\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c80fa9-23d6-4d34-a91c-39a83877d6f0",
   "metadata": {
    "papermill": {
     "duration": 2.343923,
     "end_time": "2021-06-28T13:07:01.190047",
     "exception": false,
     "start_time": "2021-06-28T13:06:58.846124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "3                      0.0                      0.0  ...   \n",
       "4                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"/Users/Graduate/Desktop/ds_proj_data/santander_satisfaction/train.csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-cooperation",
   "metadata": {
    "papermill": {
     "duration": 0.019502,
     "end_time": "2021-06-28T13:07:01.276233",
     "exception": false,
     "start_time": "2021-06-28T13:07:01.256731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Initial Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abstract-animation",
   "metadata": {
    "papermill": {
     "duration": 0.085369,
     "end_time": "2021-06-28T13:07:01.381347",
     "exception": false,
     "start_time": "2021-06-28T13:07:01.295978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "# General info on the dataset\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reduced-beaver",
   "metadata": {
    "papermill": {
     "duration": 1.166198,
     "end_time": "2021-06-28T13:07:02.568582",
     "exception": false,
     "start_time": "2021-06-28T13:07:01.402384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833691ae-16ab-4f44-94b2-5d72db235c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Feature Variable Analysis\n",
    "plt.pie(x=raw_data['TARGET'].value_counts(), \n",
    "        labels=['Happy', 'Unhappy'])\n",
    "plt.title(\"Distribution between Happy & Unhappy Customers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116664c9-2e52-40c8-9717-e6a1ed2c0da8",
   "metadata": {},
   "source": [
    "**Takeaway:** From the pie chart above, we can see a clear issue of class imbalance in our training dataset. Going forward, we will try mitigating that before building our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e71689-ac87-4898-89ab-2c35f555530b",
   "metadata": {},
   "source": [
    "# 5. Class Imbalance\n",
    "\n",
    "Our diagnostics observed a class imbalance between happy and unhappy customers. Given the limited pool of examples to train, it poses an issue in terms of building an effective machine model to predict accurately the unhappy customers. With the minority target being so small, we would expect poor performance on the critical task of detecting fraud transactions. In that vein, we will use different sampling methods (Undersampling & Oversampling) to tackle this problem.\n",
    "\n",
    "**Definitions:** \n",
    "* **SMOTE** (Synthetic Minority Oversampling Technique) is an oversampling approach to the minority target. In context, it would mean to randomly increase fraud examples by \"artificially\" replicating to have a more balanced target distribution. Further information [here](https://rikunert.com/smote_explained).\n",
    "* **Near-Miss Algorithm** is an undersampling approach on the majority target. In context, we select examples to keep out of the training set based on the distance of majority target examples to minority target examples. Further information [here](https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-targetification/).\n",
    "* **Combine over- and uner- sampling**: With the risk of overfitting with oversampling and the possibility to lose valuable information from undersampling, we will also consider combining both to rebalance the distribution. So, we shall proceed with the combination to offer curve out the risks we identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4463933e-7342-4197-9f2c-3be6161dc3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_imbalance(data, sampling_methods={'SMOTE': SMOTE(), 'Near-Miss': NearMiss(),\n",
    "                                            'over': RandomOverSampler(sampling_strategy=0.5),\n",
    "                                            'under':RandomUnderSampler(sampling_strategy=0.8)}):\n",
    "    \"\"\" Mitigate the risk of poor model performance using re-sampling methods\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dataframe\n",
    "        A dataset\n",
    "    \n",
    "    sampling_methods: dictionary\n",
    "        Key-pair values of under- and over- sampling methods\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_sampled, y_sampled: arrays of values\n",
    "        Feature(s) and Target variable respectively with sampling methods done\n",
    "    \"\"\"\n",
    "    # Splitting features & target variable\n",
    "    X = data.drop(columns=['TARGET'], axis=1)\n",
    "    y = data['TARGET']\n",
    "    \n",
    "    #Testing SMOTE() and Near-Miss() Algorithms\n",
    "    sampling_alg = [sampling_methods['SMOTE'], sampling_methods['Near-Miss']]\n",
    "\n",
    "    for alg in sampling_alg:\n",
    "        X_new, y_new = alg.fit_resample(X, y)\n",
    "        bal = y_new.value_counts(normalize=True) * 100\n",
    "        \n",
    "        print(f'''Shape of X before {alg}: {X.shape} Shape of X after {alg}: {X_new.shape}''')\n",
    "        print(f'\\nBalance of positive and negative classes (%): \\n{bal}\\n')\n",
    "    \n",
    "    ## Combined Sampling: Random Sampling Algorithms\n",
    "    X_over, y_over = sampling_methods['over'].fit_resample(X, y)\n",
    "    X_sampled, y_sampled = sampling_methods['under'].fit_resample(X_over, y_over)\n",
    "    \n",
    "    bal = y_sampled.value_counts(normalize=True) * 100\n",
    "    print(f'''After combined sampling, shape of features: {X_sampled.shape}''')\n",
    "    print(f'\\nBalance of positive and negative classes (%): \\n{bal}\\n')\n",
    "        \n",
    "    return X_sampled, y_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c2ce1e2-8691-4d14-8eed-ce6ab08dcab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X before SMOTE(): (76020, 370) Shape of X after SMOTE(): (146024, 370)\n",
      "\n",
      "Balance of positive and negative classes (%): \n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Shape of X before NearMiss(): (76020, 370) Shape of X after NearMiss(): (6016, 370)\n",
      "\n",
      "Balance of positive and negative classes (%): \n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "After combined sampling, shape of features: (82138, 370)\n",
      "\n",
      "Balance of positive and negative classes (%): \n",
      "0    55.555285\n",
      "1    44.444715\n",
      "Name: TARGET, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = class_imbalance(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778da605-ff3d-4a53-ab22-4f6246bcb474",
   "metadata": {},
   "source": [
    "# 6. Dimensionality Reduction\n",
    "\n",
    "This section will use dimensionality reduction to trim down the number of features we have. Dimensionality reduction encapsulates the techniques reducing the input variables in our training data. In doing so, we hope to have a more straightforward but effective machine learning model structure and avoid any potential case of overfitting. We will be testing three different methods from Linear Algebra: **PCA, SVD, and LDA** and pick the one capturing the most variability in the datasets after reducing it to principal components.\n",
    "* **PCA** (Principal Component Analysis) takes data with m-columns projected to a subspace with n-features (n < m) while preserving the crucial information from the original data; in other words, PCA attempts to find the **principal components (or features)** as its names denote. Further information [here](https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/). \n",
    "* **SVD** (Singular Value Decomposition) is a process breaking down a matrix into its constituents elements by factorizing it into three separate matrices: **M=UÎ£Váµ—**. Further information [here](https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/). \n",
    "    * M: original matrix\n",
    "    * U: left singular matrix (columns are left singular vectors) containing eigenvectors of matrix MMáµ—\n",
    "    * Î£: a diagonal matrix containing singular (eigen)values\n",
    "    * V: right singular matrix (columns are right singular vectors) containing  eigenvectors of matrix Máµ—M.\n",
    "* **Factor Analysis** is a technique that is used to reduce a large number of variables into fewer numbers of factors.  This technique extracts maximum common variance from all variables and puts them into a common score.  As an index of all variables, we can use this score for further analysis. Futher information [here](https://www.alchemer.com/resources/blog/factor-analysis/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e98b3fc6-dc33-46d2-a0dd-ae886d5c3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionality_reduction(X, n=5,\n",
    "                             dimred_methods={'PCA':PCA(),'SVD':TruncatedSVD()}):\n",
    "    \"\"\" Deal with the multiple anonymized variables using dimensionality reduction\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: Array\n",
    "        Feature(s)\n",
    "        \n",
    "    n: Discrete number\n",
    "        Reduce the total number of features into n components\n",
    "        \n",
    "    dimred_methods: dictionary\n",
    "        Key-pair values of dimensionality reduction methods\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X, y\n",
    "        Final Feature(s) and Target variables after dimensionality reduction\n",
    "    \"\"\"\n",
    "    \n",
    "    name, result = '', 0\n",
    "    for method_name, method_func in dimred_methods.items():\n",
    "        method_func.n_components = n\n",
    "        method_func.fit_transform(X)\n",
    "        exp_var = np.sum(method_func.explained_variance_ratio_)\n",
    "        if exp_var > result:\n",
    "            name = method_name \n",
    "            result = exp_var\n",
    "        else:\n",
    "            continue\n",
    "    final = dimred_methods[name]\n",
    "    final.n_components = n\n",
    "    \n",
    "    return final.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eddf4805-a16a-4321-8b8f-0c5aabef0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_red = dimensionality_reduction(X, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f47410a-4222-4700-aba7-3ab763417d23",
   "metadata": {},
   "source": [
    "# 3. Machine Learning set-up\n",
    "\n",
    "Under this section, we will explain the procedure of two main splitting approach to estimate our models' performance. \n",
    "\n",
    "**Model Selection methods:** \n",
    "* **Train_test_split**: Often denoted as the most popular by its simplicity, the train-test split is a sampling technique dividing the dataset between training and testing sets. In doing so, the goal would be to have enough (but not too much) in our training set used for the machine learning model to predict the observations in the testing set as accurately as possible. Most would opt for a 70/30 training-testing split, respectively, others 80/20, 60/40, or whichever else works best for the case scenario. Further information [here](https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/). \n",
    "\n",
    "* **Cross-validation**: As the name would suggest, we will engage here in the process of validation to ensure reliability on our model. Cross-Validation is a statistical method applied in various ways to estimate the model's performance. Some examples are **Holdout Method, K-Fold, Stratified K-Fold, Leave-P-Out.**  Further information [here](https://machinelearningmastery.com/k-fold-cross-validation/) and [here](https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1fa9d50-5367-43b5-99bb-f83082b43ba5",
   "metadata": {
    "papermill": {
     "duration": 0.027401,
     "end_time": "2021-06-28T13:34:56.587455",
     "exception": false,
     "start_time": "2021-06-28T13:34:56.560054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_comparison(X, y, models, \n",
    "                     metric='roc_auc'):\n",
    "    \n",
    "    \"\"\" Function to split data into training and testing set\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "        A dataset\n",
    "    models: A dictionary\n",
    "        A pre-defined dictionary with each model name and applicable function\n",
    "    \n",
    "    optional train_test params\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    models_df\n",
    "        A dataframe with each model performance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Splitting features & target variable\n",
    "    # X = df.drop(columns=['TARGET'], axis=1)\n",
    "    # y = df['TARGET']\n",
    "    \n",
    "    # Obtain training and testing sets from function above\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    # Craete dictionary to save performance data \n",
    "    avg, sd = 'mean_'+metric, 'std_'+metric\n",
    "    models_perf = {'Models': [], avg: [], sd: []}\n",
    "    \n",
    "    # Obtain model performance across K-Fold using Cross-Validation \n",
    "    for model in models:\n",
    "        cv_results = cross_validate(model, X, y, \n",
    "                                    cv=2, scoring=metric)\n",
    "        cv_metric = np.sqrt(abs(cv_results['test_score']))\n",
    "        m = str(model)\n",
    "        m = m[m.find(\".\")+1:m.find(\"(\")]\n",
    "        models_perf['Models'].append(m)\n",
    "        models_perf[avg].append(np.mean(cv_metric))\n",
    "        models_perf[sd].append(np.std(cv_metric))\n",
    "        print(m, \"successfully built\")\n",
    "    models_df = pd.DataFrame(models_perf, columns = ['Models', avg, sd])\n",
    "    return models_df.sort_values(by=avg, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93da892-ee40-43cc-9412-c9232011256d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:34:56.646968Z",
     "iopub.status.busy": "2021-06-28T13:34:56.646434Z",
     "iopub.status.idle": "2021-06-28T13:34:56.692180Z",
     "shell.execute_reply": "2021-06-28T13:34:56.691733Z",
     "shell.execute_reply.started": "2021-06-28T12:47:32.784942Z"
    },
    "papermill": {
     "duration": 0.077074,
     "end_time": "2021-06-28T13:34:56.692282",
     "exception": false,
     "start_time": "2021-06-28T13:34:56.615208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Machine Learning - Model Building\n",
    "\n",
    "* **Simple Methods:** We will leverage the powerful sci-kit-learn package to build multiple models with little to no parameter tuning for comparison. We will only use the cross-validation error on our training dataset to avoid any data leakage.\n",
    "\n",
    "* **Ensemble Methods:** We will extend our work in machine learning to incorporate ensemble methods. We generated simple models and compared the scores, which appear satisfactory; however, we may want more stability and minor variation in our predictive algorithm; it is where ensemble techniques come in. Most often, they act as a 'superposer' of multiple models throughout various ways and thus, bolster their predictive power. Further Information [here](https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "velvet-reaction",
   "metadata": {
    "papermill": {
     "duration": 2.849853,
     "end_time": "2021-06-28T13:34:59.569659",
     "exception": false,
     "start_time": "2021-06-28T13:34:56.719806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression successfully built\n",
      "KNeighborsClassifier successfully built\n",
      "DecisionTreeClassifier successfully built\n",
      "GaussianNB successfully built\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>mean_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.975457</td>\n",
       "      <td>0.000532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.971457</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.773305</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.719752</td>\n",
       "      <td>0.002069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Models  mean_roc_auc  std_roc_auc\n",
       "2  DecisionTreeClassifier      0.975457     0.000532\n",
       "1    KNeighborsClassifier      0.971457     0.000064\n",
       "0      LogisticRegression      0.773305     0.000035\n",
       "3              GaussianNB      0.719752     0.002069"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple ML Models\n",
    "models_simple = [LogisticRegression(), \n",
    "                 KNeighborsClassifier(n_neighbors=2),\n",
    "                 DecisionTreeClassifier(), GaussianNB()]\n",
    "\n",
    "# Model Comparison\n",
    "model_comparison(X, y, models_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "770448fc-5a27-4e53-9628-afb938771f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier successfully built\n",
      "BaggingClassifier successfully built\n",
      "AdaBoostClassifier successfully built\n",
      "GradientBoostingClassifier successfully built\n",
      "XGBClassifier successfully built\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>mean_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.998585</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.967563</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.926718</td>\n",
       "      <td>0.000587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.915702</td>\n",
       "      <td>0.000843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Models  mean_roc_auc  std_roc_auc\n",
       "0      RandomForestClassifier      0.999676     0.000107\n",
       "1           BaggingClassifier      0.998585     0.000129\n",
       "4               XGBClassifier      0.967563     0.000356\n",
       "3  GradientBoostingClassifier      0.926718     0.000587\n",
       "2          AdaBoostClassifier      0.915702     0.000843"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # List of ML ensemble models\n",
    "models_ensemble = [esmb.RandomForestClassifier(), esmb.BaggingClassifier(),\n",
    "                   esmb.AdaBoostClassifier(), esmb.GradientBoostingClassifier(), \n",
    "                   XGBClassifier(objective='binary:logistic', \n",
    "                                 eval_metric='logloss')]\n",
    "\n",
    "# Model Comparison\n",
    "model_comparison(X, y, models_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unknown-accountability",
   "metadata": {
    "papermill": {
     "duration": 0.119775,
     "end_time": "2021-06-28T13:38:39.466899",
     "exception": false,
     "start_time": "2021-06-28T13:38:39.347124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result.to_csv('sample_submission.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1910.382298,
   "end_time": "2021-06-28T13:38:40.405682",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-28T13:06:50.023384",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
